@article{abboub2016prosodica,
  title = {Prosodic Grouping at Birth},
  author = {Abboub, Nawal and Nazzi, Thierry and Gervain, Judit},
  year = 2016,
  journal = {Brain and language},
  volume = {162},
  pages = {46--59},
  publisher = {Elsevier}
}

@article{berent2010universal,
  title = {Universal Constraints on the Sound Structure of Language: {{Phonological}} or Acoustic?},
  shorttitle = {Universal Constraints on the Sound Structure of Language},
  author = {Berent, Iris and Lennertz, Tracy},
  year = 2010,
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {36},
  number = {1},
  pages = {212--223},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1277},
  doi = {10.1037/a0017638},
  abstract = {Languages are known to exhibit universal restrictions on sound structure. The source of such restrictions, however, is contentious: Do they reflect abstract phonological knowledge, or properties of linguistic experience and auditory perception? We address this question by investigating the restrictions on onset structure. Across languages, onsets of small sonority distances are dispreferred (e.g., lb is dispreferred to bn). Previous research with aural materials demonstrates such preferences modulate the perception of unattested onsets by English speakers: Universally ill-formed onsets are systematically misperceived (e.g., lba {$\rightarrow$} leba) relative to well-formed onsets (e.g., bn). Here, we show that the difficulty to process universally ill-formed onsets extends to printed materials. Auxiliary tests indicate that such difficulties reflect phonological, rather than orthographic knowledge, and regression analyses demonstrate such knowledge goes beyond the statistical properties of the lexicon. These findings suggest that speakers have abstract, possibly universal, phonological knowledge that is general with respect to input modality. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Acoustics,Auditory Perception,Auditory Stimulation,Language,Linguistics,Phonology,Reading,Theories}
}

@article{berent2011phonological,
  title = {Phonological {{Universals}} in {{Early Childhood}}: {{Evidence}} from {{Sonority Restrictions}}},
  shorttitle = {Phonological {{Universals}} in {{Early Childhood}}},
  author = {Berent, Iris and Harder, Katherine and Lennertz, Tracy},
  year = 2011,
  journal = {Language Acquisition},
  volume = {18},
  number = {4},
  eprint = {41308789},
  eprinttype = {jstor},
  pages = {281--293},
  publisher = {Taylor \& Francis, Ltd.},
  issn = {1048-9223},
  doi = {10.1080/10489223.2011.580676},
  urldate = {2025-06-20},
  abstract = {Across languages, onsets with large sonority distances are preferred to those with smaller distances (e. g., bw{$>$} bd{$>$}lb; Greenberg 1978). Optimality Theory (Prince \& Smolensky 2004) attributes such facts to grammatical restrictions that are universally active in all grammars. To test this hypothesis, here we examine whether children extend putatively universal sonority restrictions to onsets unattested in their language. Participants (M = 4;03) were presented with pairs of auditory words--- either identical (e.g., lbif{$\rightarrow$}lbif) or epenthetically related (e. g., lbif{$\rightarrow$}lebif)---and asked to judge heir identity. Results showed that, like adults, children's ability to detect epenthetic distortions was monotonically related to sonority distance (bw{$>$}bd{$>$}lb), and their performance was inexplicable by several statistical and phonetic factors. These findings suggest that sonority restrictions are active in early childhood, and their scope is broad.},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/VPD57UXB/Berent et al. - 2011 - Phonological Universals in Early Childhood Eviden.pdf}
}

@article{bertoncini1988investigation,
  title = {An Investigation of Young Infants' Perceptual Representations of Speech Sounds},
  author = {Bertoncini, J. and {Bijeljac-Babic}, R. and Jusczyk, P. W. and Kennedy, L. J. and Mehler, J.},
  year = 1988,
  journal = {Journal of Experimental Psychology: General},
  volume = {117},
  number = {1},
  pages = {21}
}

@article{best1995divergenta,
  title = {Divergent Developmental Pattern for Infants'perception of Two Non Native Consonant Contrasts},
  author = {Best, Catherine T. and McRoberts, Gerald W. and LaFleur, Rosemarie and {Silver-Isenstadt}, Jean},
  year = 1995,
  journal = {Infant Behavior and Development},
  volume = {18},
  pages = {339--350},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/MPCV39B2/Best et al. - 1995 - Divergent developmental pattern for infants'percep.pdf}
}

@article{best2001discrimination,
  title = {Discrimination of Non-Native Consonant Contrasts Varying in Perceptual Assimilation to the Listener's Native Phonological System},
  author = {Best, Catherine T. and McRoberts, Gerald W. and Goodell, Elizabeth},
  year = 2001,
  journal = {Journal of the Acoustical Society of America},
  volume = {109},
  number = {2},
  pages = {775--794},
  abstract = {Classic non-native speech perception findings suggested that adults have difficulty discriminating segmental distinctions that are not employed contrastively in their own language. However, recent reports indicate a gradient of performance across non-native contrasts, ranging from near-chance to near-ceiling. Current theoretical models argue that such variations reflect systematic effects of experience with phonetic properties of native speech. The present research addressed predictions from Best's perceptual assimilation model (PAM), which incorporates both contrastive phonological and noncontrastive phonetic influences from the native language in its predictions about discrimination levels for diverse types of non-native contrasts. We evaluated the PAM hypotheses that discrimination of a non-native contrast should be near-ceiling if perceived as phonologically equivalent to a native contrast, lower though still quite good if perceived as a phonetic distinction between good versus poor exemplars of a single native consonant, and much lower if both non-native segments are phonetically equivalent in goodness of fit to a single native consonant. Two experiments assessed native English speakers' perception of Zulu and Tigrinya contrasts expected to fit those criteria. Findings supported the PAM predictions, and provided evidence for some perceptual differentiation of phonological, phonetic, and nonlinguistic information in perception of non-native speech. Theoretical implications for non-native speech perception are discussed, and suggestions are made for further research.}
}

@article{BOSCH199733,
  title = {Native-Language Recognition Abilities in 4-Month-Old Infants from Monolingual and Bilingual Environments},
  author = {Bosch, Laura and {Sebasti{\'a}n-Gall{\'e}s}, N{\'u}ria},
  year = 1997,
  journal = {Cognition},
  volume = {65},
  number = {1},
  pages = {33--69},
  issn = {0010-0277},
  doi = {10.1016/S0010-0277(97)00040-1},
  abstract = {This study examined the capacity of 4-month-old infants to identify their maternal language when phonologically similar languages are contrasted, using a visual orientation procedure with a reaction time measure. Infants from monolingual and bilingual environments were compared in order to analyze whether differences in linguistic background affect this behavioral response. In experiment 1 the validity of the procedure was assessed with a pair of phonologically dissimilar languages (Catalan or Spanish vs. English). In experiment 2, 20 infants from monolingual environments tested in a similar language contrast (Catalan vs. Spanish) indicated that discrimination is already possible at that age. Results from experiment 3, using low-pass filtered utterances, suggested that infants can rely on information about supra-segmental features to make this distinction. For the infants growing up in bilingual environments no preference for either of the familiar languages was found. Moreover, when their maternal language was contrasted either with English or with Italian, in both cases the bilingual group showed a similar pattern, consisting of significantly longer latencies for the familiar language. Possible interpretations of this unexpected pattern of results are discussed and its implications for bilingual language acquisition are considered.},
  keywords = {Bilingual,Infants,Language recognition,Monolingual}
}

@article{bosch2001evidencea,
  title = {Evidence of {{Early Language Discrimination Abilities}} in {{Infants From Bilingual Environments}}},
  author = {Bosch, Laura and Sebasti{\'a}n-Gall{\'e}s, N{\'u}ria},
  year = 2001,
  journal = {Infancy},
  volume = {2},
  number = {1},
  pages = {29--49},
  issn = {1532-7078},
  doi = {10.1207/S15327078IN0201_3},
  urldate = {2020-01-21},
  abstract = {Previous research data indicate that soon after birth, infants from monolingual families can discriminate utterances drawn from languages that differ prosodically, but discrimination between rhythmically similar languages, such as English and Dutch, has not yet been established by 2 months of age. In the case of bilinguals, the question of how early they can distinguish between the languages of exposure remains unanswered. The goal of this study was to analyze language discrimination capacities in 4-month-old bilingual infants simultaneously exposed to 2 Romance languages belonging to the same rhythmic category, Spanish and Catalan. Using a familiarization-preference procedure, 2 groups of bilingual-to-be infants showed a capacity to discriminate between these 2 familial languages. Moreover, when compared with 2 groups of infants from monolingual environments, the size of the observed effects was the same. These results can be taken as initial evidence of an early capacity to distinguish languages in simultaneous bilingual exposure, thus challenging the hypothesis that language discrimination capacities are delayed in bilinguals.},
  copyright = {2001 International Society on Infant Studies},
  langid = {english},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/NIJ33XSF/Bosch and Sebastián‐Gallés - 2001 - Evidence of Early Language Discrimination Abilitie.pdf}
}

@article{cutler1993mora,
  title = {Mora or Syllable? {{Speech}} Segmentation in {{Japanese}}},
  author = {Cutler, Anne and Mehler, Jacques and Otake, Takashi and Hatano, Giyoo},
  year = 1993,
  month = apr,
  journal = {Journal of Memory and Language},
  volume = {32},
  number = {2},
  pages = {258},
  langid = {english},
  keywords = {4019: psycholinguistics,article,empirical data,Japanese (39500),Japanese speakers' mora use,Linguistics,Mora (55200),Native Speakers (56450),native/nonnative Japanese speakers,phonological processing,Phonological Processing (65110),speech segmentation,subsyllabic unit}
}

@article{decasper1986prenatal,
  title = {Prenatal Maternal Speech Influences Newborns' Perception of Speech Sounds},
  author = {DeCasper, Anthony J. and Spence, Melanie J.},
  year = 1986,
  journal = {Infant Behavior and Development},
  volume = {9},
  number = {2},
  pages = {133--150},
  issn = {01636383},
  doi = {10.1016/0163-6383(86)90025-1},
  abstract = {Pregnant women recited a particular speech passage aloud each day during their last 6 weeks of pregnancy. Their newborns were tested with an operant-choice procedure to determine whether the sounds of the recited passage were more reinforcing than the sounds of a novel passage. The previously recited passage was more reinforcing. The reinforcing value of the two passages did not differ for a matched group of control subjects. Thus, third-trimester fetuses experience their mothers' speech sounds and that prenatal auditory experience can influence postnatal auditory preferences. \copyright{} 1986.},
  keywords = {auditory perception,fetal experience,maternal voice,newborn perception,prenatal learning,prenatal sensory experience,speech perception}
}

@article{fedorenko2024language,
  title = {Language Is Primarily a Tool for Communication Rather than Thought},
  author = {Fedorenko, Evelina and Piantadosi, Steven T. and Gibson, Edward A. F.},
  year = 2024,
  month = jun,
  journal = {Nature},
  volume = {630},
  number = {8017},
  pages = {575--586},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-024-07522-w},
  urldate = {2026-02-09},
  abstract = {Language is a defining characteristic of our species, but the function, or functions, that it serves has been debated for centuries. Here we bring recent evidence from neuroscience and allied disciplines to argue that in modern humans, language is a tool for communication, contrary to a prominent view that we use language for thinking. We begin by introducing the brain network that supports linguistic ability in humans. We then review evidence for a double dissociation between language and thought, and discuss several properties of language that suggest that it is optimized for communication. We conclude that although the emergence of language has unquestionably transformed human culture, language does not appear to be a prerequisite for complex thought, including symbolic thought. Instead, language is a powerful tool for the transmission of cultural knowledge; it plausibly co-evolved with our thinking and reasoning capacities, and only reflects, rather than gives rise to, the signature sophistication of human cognition.},
  copyright = {2024 Springer Nature Limited},
  langid = {english},
  keywords = {Human behaviour,Language}
}

@article{ferry2016edge,
  title = {On the Edge of Language Acquisition: Inherent Constraints on Encoding Multisyllabic Sequences in the Neonate Brain},
  shorttitle = {On the Edge of Language Acquisition},
  author = {Ferry, Alissa L. and Fl{\'o}, Ana and Brusini, Perrine and Cattarossi, Luigi and Macagno, Francesco and Nespor, Marina and Mehler, Jacques},
  year = 2016,
  journal = {Developmental Science},
  volume = {19},
  number = {3},
  pages = {488--503},
  issn = {1467-7687},
  doi = {10.1111/desc.12323},
  urldate = {2024-10-10},
  abstract = {To understand language, humans must encode information from rapid, sequential streams of syllables -- tracking their order and organizing them into words, phrases, and sentences. We used Near-Infrared Spectroscopy (NIRS) to determine whether human neonates are born with the capacity to track the positions of syllables in multisyllabic sequences. After familiarization with a six-syllable sequence, the neonate brain responded to the change (as shown by an increase in oxy-hemoglobin) when the two edge syllables switched positions but not when two middle syllables switched positions (Experiment 1), indicating that they encoded the syllables at the edges of sequences better than those in the middle. Moreover, when a 25 ms pause was inserted between the middle syllables as a segmentation cue, neonates' brains were sensitive to the change (Experiment 2), indicating that subtle cues in speech can signal a boundary, with enhanced encoding of the syllables located at the edges of that boundary. These findings suggest that neonates' brains can encode information from multisyllabic sequences and that this encoding is constrained. Moreover, subtle segmentation cues in a sequence of syllables provide a mechanism with which to accurately encode positional information from longer sequences. Tracking the order of syllables is necessary to understand language and our results suggest that the foundations for this encoding are present at birth.},
  copyright = {\copyright{} 2015 John Wiley \& Sons Ltd},
  langid = {english},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/KEBJPPBA/Ferry et al. - 2016 - On the edge of language acquisition inherent cons.pdf;/home/gongcastro/snap/zotero-snap/common/Zotero/storage/Y24GPGQC/desc.html}
}

@article{flo2019newborns,
  title = {Newborns Are Sensitive to Multiple Cues for Word Segmentation in Continuous Speech},
  author = {Fl{\'o}, Ana and Brusini, Perrine and Macagno, Francesco and Nespor, Marina and Mehler, Jacques and Ferry, Alissa L.},
  year = 2019,
  journal = {Developmental Science},
  volume = {22},
  number = {4},
  pages = {e12802},
  issn = {1467-7687},
  doi = {10.1111/desc.12802},
  urldate = {2024-10-02},
  abstract = {Before infants can learn words, they must identify those words in continuous speech. Yet, the speech signal lacks obvious boundary markers, which poses a potential problem for language acquisition (Swingley, Philos Trans R Soc Lond. Series B, Biol Sci 364(1536), 3617--3632, 2009). By the middle of the first year, infants seem to have solved this problem (Bergelson \& Swingley, Proc Natl Acad Sci 109(9), 3253--3258, 2012; Jusczyk \& Aslin, Cogn Psychol 29, 1--23, 1995), but it is unknown if segmentation abilities are present from birth, or if they only emerge after sufficient language exposure and/or brain maturation. Here, in two independent experiments, we looked at two cues known to be crucial for the segmentation of human speech: the computation of statistical co-occurrences between syllables and the use of the language's prosody. After a brief familiarization of about 3 min with continuous speech, using functional near-infrared spectroscopy, neonates showed differential brain responses on a recognition test to words that violated either the statistical (Experiment 1) or prosodic (Experiment 2) boundaries of the familiarization, compared to words that conformed to those boundaries. Importantly, word recognition in Experiment 2 occurred even in the absence of prosodic information at test, meaning that newborns encoded the phonological content independently of its prosody. These data indicate that humans are born with operational language processing and memory capacities and can use at least two types of cues to segment otherwise continuous speech, a key first step in language acquisition.},
  langid = {english},
  keywords = {fNIRS,language acquisition,newborns,prosody,speech segmentation,statistical learning},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/NIGVPE7Z/Fló et al. - 2019 - Newborns are sensitive to multiple cues for word s.pdf;/home/gongcastro/snap/zotero-snap/common/Zotero/storage/SUUIB386/Fló et al. - 2019 - Newborns are sensitive to multiple cues for word segmentation in continuous speech.pdf;/home/gongcastro/snap/zotero-snap/common/Zotero/storage/W9X842JQ/Fló et al. - 2019 - Newborns are sensitive to multiple cues for word s.pdf;/home/gongcastro/snap/zotero-snap/common/Zotero/storage/SJZEW77P/desc.html}
}

@article{friederici1993phonotactica,
  title = {Phonotactic Knowledge of Word Boundaries and Its Use in Infant Speech Perception},
  author = {Friederici, Angela D. and Wessels, Jeanine M. I.},
  year = 1993,
  journal = {Perception \& Psychophysics},
  volume = {54},
  number = {3},
  pages = {287--295},
  issn = {00315117},
  doi = {10.3758/BF03205263},
  abstract = {The development of a lexicon critically depends on the infant's ability to identify wordlike units in the auditory speech input. The present study investigated at what age infants become sensitive to language-specific phonotactic features that signal word boundaries and to what extent they are able to use this knowledge to segment speech input. Experiment 1 showed that infants at the age of 9 months were sensitive to the phonotactic structure of word boundaries when word-like units were presented in isolation. Experiments 2 to 5 demonstrated that this sensitivity was present even when critical items were presented in context, although only under certain conditions. Preferences for legal over illegal word boundary clusters were found when critical items were embedded in two identical syllables, keeping language processing requirements and attentional requirements low. Experiment 6 replicated the findings of Experiment 1. Experiment 7 was a low-pass-filtered version of Experiment 6 that left the prosody of the stimulus items intact while removing most of the distinctive phonotactic cues. As expected, no listening preference for legal over illegal word boundary clusters was found in this experiment. This clearly suggests that the preferential patterns observed can be attributed to the infants' sensitivity to phonotactic constraints on word boundaries in a given language and not to suprasegmental cues.},
  pmid = {8414887},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/8G5LUUNL/Friederici and Wessels - 1993 - Phonotactic knowledge of word boundaries and its u.pdf}
}

@article{friederici2005neurophysiological,
  title = {Neurophysiological Markers of Early Language Acquisition: From Syllables to Sentences},
  author = {Friederici, A.},
  year = 2005,
  journal = {Trends in cognitive sciences},
  volume = {9},
  number = {10},
  pages = {481--488}
}

@article{gervain2008neonate,
  title = {The Neonate Brain Detects Speech Structure},
  author = {Gervain, J. and Macagno, F. and Cogoi, S. and Pe{\~n}a, M. and Mehler, J.},
  year = 2008,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {105},
  number = {37},
  pages = {14222--14227}
}

@article{gervain2010speech,
  title = {Speech {{Perception}} and {{Language Acquisition}} in the {{First Year}} of {{Life}}},
  author = {Gervain, Judit and Mehler, Jacques},
  year = 2010,
  journal = {Annual Review of Psychology},
  volume = {61},
  number = {1},
  pages = {191--218},
  issn = {0066-4308},
  doi = {10.1146/annurev.psych.093008.100408},
  abstract = {During the first year of life, infants pass important milestones in language development. We review some of the experimental evidence concerning these milestones in the domains of speech perception, phonological development, word learning, morphosyntactic acquisition, and bilingualism, emphasizing their interactions. We discuss them in the context of their biological underpinnings, introducing the most recent advances not only in language development, but also in neighboring areas such as genetics and the comparative research on animal communication systems. We argue for a theory of language acquisition that integrates behavioral, cognitive, neural, and evolutionary considerations and proposes to unify previously opposing theoretical stances, such as statistical learning, rule-based nativist accounts, and perceptual learning theories.},
  pmid = {19575623},
  keywords = {evolution,infancy,learning mechanisms,phonological bootstrapping}
}

@article{gomez2014language,
  title = {Language Universals at Birth},
  author = {Gomez, D. and Berent, I. and {Benavides-Varela}, S. and Bion, R. and Cattarossi, L. and Nespor, M. and Mehler, J.},
  year = 2014,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {16},
  pages = {5837--5841}
}

@article{jusczyk1987representation,
  title = {Representation of Speech Sounds by Young Infants},
  author = {Jusczyk, Peter W and Derrah, Cynthia},
  year = 1987,
  journal = {Developmental Psychology},
  volume = {23},
  number = {5},
  pages = {648},
  publisher = {American Psychological Association}
}

@article{jusczyk1994infantsa,
  title = {Infants' {{Sensitivity}} to {{Phonotactic Patterns}} in the {{Native Language}}},
  author = {Jusczyk, Peter W. and Luce, Paul A.},
  year = 1994,
  journal = {Journal of Memory and Language},
  volume = {33},
  pages = {630--645}
}

@book{jusczyk1995infantsa,
  title = {Infants' {{Detection}} of the {{Sound Patterns}} of {{Words}} in {{Fluent Speech}}},
  author = {Jusczyk, Peter W. and Aslin, Richard N.},
  year = 1995,
  volume = {29},
  doi = {10.1006/cogp.1995.1010},
  abstract = {A series of four experiments examined infants' capacities to detect repeated words in fluent speech. In Experiment 1, 7 1 2-month old American infants were familiarized with two different monosyllabic words and subsequently were presented with passages which either included or did not include the familiar target words embedded in sentences. The infants listened significantly longer to the passages containing the familiar target words than to passages containing unfamiliar words. A comparable experiment with 6-month-olds provided no indication that infants at this age detected the target words in the passages. In Experiment 3, a group of 7 1 2-month-olds was familiarized with two different non-word targets which differed in their initial phonetic segment by only one or two phonetic features from words presented in two of the passages. These infants showed no tendency to listen significantly longer to the passages with the similar sounding words, suggesting that the infants may be matching rather detailed information about the items in the familiarization period to words in the test passages. Finally, Experiment 4 demonstrated that even when the 7 1 2-month-olds were initially familiarized with target words in sentential contexts rather than in isolation, they still showed reliable evidence of recognizing these words during the test phase. Taken together, the results of these studies suggest that some ability to detect words in fluent speech contexts is present by 7 1 2 months of age. \copyright{} 1995 Academic Press, Inc.},
  isbn = {0010-0285 (Print)\$\textbackslash backslash\$n0010-0285 (Linking)},
  pmid = {7641524},
  keywords = {bilingualism,Grammar,Language Arts & Disciplines / Linguistics / General,Language Arts & Disciplines / Linguistics / Psycholinguistics,Linguistics,Mathematics / Probability & Statistics / General,methods,Political Science / General,Probability,Psychology / Assessment,Psychology / Assessment Testing & Measurement,Psychology / Cognitive Psychology,Psychology / Cognitive Psychology & Cognition,Psychology / General,Psychology / Research & Methodology,Science / Cognitive Science,Science / Life Sciences / Biology,Science / Life Sciences / Developmental Biology,Science / Life Sciences / Neuroscience,Social Science / Research,Testing & Measurement}
}

@article{kuhl2006infantsa,
  title = {Infants Show a Facilitation Effect for Native Language Phonetic Perception between 6 and 12 Months},
  author = {Kuhl, Patricia K. and Stevens, Erica and Hayashi, Akiko and Deguchi, Toshisada and Kiritani, Shigeru and Iverson, Paul},
  year = 2006,
  journal = {Developmental Science},
  volume = {9},
  number = {2},
  pages = {13--21},
  issn = {1363755X},
  doi = {10.1111/j.1467-7687.2006.00468.x},
  pmid = {16472309},
  keywords = {bilingualism},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/DF5368T7/Kuhl et al. - 2006 - Infants show a facilitation effect for native lang.pdf}
}

@article{maye2002infanta,
  title = {Infant Sensitivity to Distributional Information Can Affect Phonetic Discrimination},
  author = {Maye, Jessica and Werker, Janet F. and Gerken, LouAnn},
  year = 2002,
  month = jan,
  journal = {Cognition},
  volume = {82},
  number = {3},
  pages = {101--111},
  doi = {10.1016/S0010-0277(01)00157-3},
  langid = {english},
  keywords = {2820:Cognitive & Perceptual Development,article,Attention,Auditory Discrimination,Childhood (birth-12 yrs),Empirical Study,Female,Human,Humans,Infancy (2-23 mo),Infant,Language Development,Male,Mental Recall,phonetic discrimination,Phonetics,Psycholinguistics,Speech Perception,Stochastic Modeling,stochastic patterns,tracking}
}

@article{mazuka2011development,
  title = {The Development of a Phonological Illusion: A Cross-Linguistic Study with {{Japanese}} and {{French}} Infants},
  author = {Mazuka, Reiko and Cao, Ying and Dupoux, Emmanuel and Christophe, Anne},
  year = 2011,
  journal = {Developmental science},
  volume = {14},
  number = {4},
  pages = {693--699},
  publisher = {Wiley Online Library},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/F8FVS8VI/Mazuka et al. - 2011 - The development of a phonological illusion a cros.pdf}
}

@article{mehler1988precursor,
  title = {A Precursor of Language Acquisition in Young Infants},
  author = {Mehler, Jacques and Jusczyk, Peter W. and Lambertz, Ghislaine and Halsted, Nilofar and Bertoncini, Josiane and {Amiel-Tison}, Claudine},
  year = 1988,
  journal = {Cognition},
  volume = {29},
  number = {2},
  pages = {143--178},
  issn = {00100277},
  doi = {10.1016/0010-0277(88)90035-2},
  pmid = {3168420}
}

@article{murphy2022model,
  title = {A Model for Learning Strings Is Not a Model of Language},
  author = {Murphy, Elliot and Leivada, Evelina},
  year = 2022,
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {23},
  pages = {e2201651119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2201651119},
  urldate = {2026-02-09},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/RHETVVRT/Murphy and Leivada - 2022 - A model for learning strings is not a model of language.pdf}
}

@article{piantadosi2017infinitely,
  title = {Infinitely Productive Language Can Arise from Chance under Communicative Pressure},
  author = {Piantadosi, Steven T. and Fedorenko, Evelina},
  year = 2017,
  month = jul,
  journal = {Journal of Language Evolution},
  volume = {2},
  number = {2},
  pages = {141--147},
  issn = {2058-4571},
  doi = {10.1093/jole/lzw013},
  urldate = {2026-02-09},
  abstract = {Human communication is unparalleled in the animal kingdom. The key distinctive feature of our language is productivity: we are able to express an infinite number of ideas using a limited set of words. Traditionally, it has been argued or assumed that productivity emerged as a consequence of very specific, innate grammatical systems. Here we formally develop an alternative hypothesis: productivity may have rather solely arisen as a consequence of increasing the number of signals (e.g. sentences) in a communication system, under the additional assumption that the processing mechanisms are algorithmically unconstrained. Using tools from algorithmic information theory, we examine the consequences of two intuitive constraints on the probability that a language will be infinitely productive. We prove that under maximum entropy assumptions, increasing the complexity of a language will not strongly pressure it to be finite or infinite. In contrast, increasing the number of signals in a language increases the probability of languages that have---in fact---infinite cardinality. Thus, across evolutionary time, the productivity of human language could have arisen solely from algorithmic randomness combined with a communicative pressure for a large number of signals.},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/7HGBD8UC/Piantadosi and Fedorenko - 2017 - Infinitely productive language can arise from chance under communicative pressure.pdf}
}

@article{pisoni1979perception,
  title = {On the {{Perception}} of {{Speech Sounds}} as {{Biologically Significant Signals}}},
  author = {Pisoni, David B.},
  year = 1979,
  journal = {Brain, Behavior and Evolution},
  volume = {16},
  number = {5-6},
  pages = {330--350},
  publisher = {Karger Publishers},
  issn = {0006-8977, 1421-9743},
  doi = {10.1159/000121875},
  urldate = {2020-09-26},
  abstract = {This paper reviews some of the major evidence and arguments currently available to support the view that human speech perception may require the use of specialized neural mechanisms for perceptual analysis. Experiments using synthetically produced speech signals with adults are briefly summarized and extensions of these results to infants and other organisms are reviewed with an emphasis towards detailing those aspects of speech perception that may require some need for specialized species-specific processors. Finally, some comments on the role of early experience in perceptual development are provided as an attempt to identify promising areas of new research in speech perception.},
  langid = {english},
  pmid = {399200},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/MUXCMRKM/Pisoni - 1979 - On the Perception of Speech Sounds as Biologically.pdf;/home/gongcastro/snap/zotero-snap/common/Zotero/storage/NABJQPY3/121875.html}
}

@article{prince2004optimality,
  title = {Optimality {{Theory}}: {{Constraint}} Interaction in Generative Grammar},
  author = {Prince, Alan and Smolensky, Paul},
  year = 2004,
  journal = {Optimality Theory in phonology: A reader},
  pages = {1--71},
  publisher = {Wiley Online Library},
  doi = {10.1002/9780470756171.ch1}
}

@article{rasanen2018pre,
  title = {Pre-Linguistic Segmentation of Speech into Syllable-like Units},
  author = {R{\"a}s{\"a}nen, Okko and Doyle, Gabriel and Frank, Michael C},
  year = 2018,
  journal = {Cognition},
  volume = {171},
  pages = {130--150},
  publisher = {Elsevier}
}

@article{saffran1996statisticala,
  title = {Statistical Learning by 8-Month-Old Infants},
  author = {Saffran, Jenny R. and Aslin, Richard N. and Newport, Elissa L.},
  year = 1996,
  month = dec,
  journal = {Science},
  volume = {274},
  number = {5294},
  pages = {1926--1928},
  doi = {10.1126/science.274.5294.1926},
  langid = {english},
  keywords = {2820:Cognitive & Perceptual Development,article,Auditory Stimulation,Childhood (birth-12 yrs),Discrimination Learning,Empirical Study,Human,Humans,Infancy (2-23 mo),Infant,Infant Development,Language Development,Learning,segmentation of words from fluent speech based on,Speech Perception,Words (Phonetic Units)},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/9GBPIIDB/Saffran et al. - 1996 - Statistical learning by 8-month-old infants.pdf}
}

@article{saffran2003syllables,
  title = {From {{Syllables}} to {{Syntax}}: {{Multilevel Statistical Learning}} by 12-{{Month-Old Infants}}},
  shorttitle = {From {{Syllables}} to {{Syntax}}},
  author = {Saffran, Jenny R. and Wilson, Diana P.},
  year = 2003,
  journal = {Infancy},
  volume = {4},
  number = {2},
  pages = {273--284},
  issn = {1525-0008},
  doi = {10.1207/S15327078IN0402_07},
  urldate = {2019-09-23},
  abstract = {To successfully acquire language, infants must be able to track multiple levels of regularities in the input. In many cases, regularities only emerge after some learning has already occurred. For example, the grammatical relationships between words are only evident once the words have been segmented from continuous speech. To ask whether infants can engage in this type of learning process, 12-month-old infants in 2 experiments were familiarized with multiword utterances synthesized as continuous speech. The words in the utterances were ordered based on a simple finite-state grammar. Following exposure, infants were tested on novel grammatical and ungrammatical sentences. The results indicate that the infants were able to perform 2 statistical learning tasks in sequence: first segmenting the words from continuous speech, and subsequently discovering the permissible orderings of the words. Given a single set of input, infants were able to acquire multiple levels of structure, suggesting that multiple levels of representation (initially syllable-level combinations, subsequently word-level combinations)can emerge during the course of learning.},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/2CN7EYBQ/Saffran and Wilson - 2003 - From Syllables to Syntax Multilevel Statistical L.pdf}
}

@article{werker1984crosslanguage,
  title = {Cross-Language Speech Perception: {{Evidence}} for Perceptual Reorganization during the First Year of Life},
  author = {Werker, Janet F. and Tees, Richard C.},
  year = 1984,
  journal = {Infant Behavior \& Development},
  volume = {7},
  number = {1},
  pages = {49--63},
  issn = {1879-0453, 1879-0453},
  doi = {http://dx.doi.org/10.1016/S0163-6383(84)80022-3},
  abstract = {Previous work in which the authors and colleagues (see record 1981-12550-001) compared English adults on their ability to discriminate 2 pairs of Hindu (non-English) speech contrasts has indicated that infants discriminate speech sounds according to phonetic category without prior specific language experience. Previous work by the authors (in press) has indicated that adults and children as young as 4 yrs may lose this ability as a function of age and/or linguistic experience. The present study examined the generalizability of such a decline by comparing 10 22--35 yr old English adults, 5 30--65 yr old Salish adults, and 58 English infants (12 6--8 mo olds, 26 8--10 mo olds, and 20 10--22 mo olds) on their perception of a new non-English (Salish) speech contrast. The time course of the developmental decline in this ability was also investigated. Results of 3 experiments replicate previous findings by showing that infants can discriminate nonnative speech contrasts without relevant experience and that there is a decline in this ability during ontogeny. Further, data from both cross-sectional and longitudinal studies show that this decline occurs within the 1st yr of life and that it is a function of specific language experience. (21 ref) (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  langid = {english},
  keywords = {2820:Cognitive & Perceptual Development,6-8,article,Childhood (birth-12 yrs),cross-language,decline,discrimination of nonnative speech contrasts,Empirical Study,Foreign Languages,Human,Infancy (2-23 mo),infants,Phonetics,Speech Development,speech perception,Speech Perception},
  file = {/home/gongcastro/snap/zotero-snap/common/Zotero/storage/UEAD48TI/S0163638384800223.html}
}
